{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA это вероятностная тематическая модель. Совместное распределение имеет следующий вид:\n",
    "$$p(W, Z, \\Theta, \\Phi | \\alpha, \\eta) = \\prod_{d=1}^D \\Big( p(\\theta_d | \\alpha) \\prod_{n=1}^{N_d} p(w_{d,n} | z_{d,n}, \\Phi) p(z_{d,n} | \\theta_d) \\Big) \\prod_{t=1}^T p(\\phi_t | \\eta) $$\n",
    "\n",
    "Где:\n",
    "$$p(\\theta_d | \\alpha) = Dir(\\theta_d | \\alpha)$$\n",
    "\n",
    "$$p(w_{d,n} | z_{d,n}, \\Phi) = Categorical(W_{d,n} | \\phi_{z_{d,n}})$$\n",
    "\n",
    "$$p(z_{d,n} | \\theta_d) = Categorical(z_{d,n} | \\theta_d)$$\n",
    "\n",
    "$$p(\\phi_t | \\eta) = Dir(\\phi_t | \\eta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании, вам предстоит применить тематическую модель LDA к датасету NIPS-papers. Нужно установить Python библиотеку `gensim` (её можно установить с помощью `pip`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import gensim\n",
    "\n",
    "import logging\n",
    "\n",
    "gensim.models.ldamodel.logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет и поместите его в папку с ноутбуком: \n",
    "http://www.cs.nyu.edu/~roweis/data/nips12raw_str602.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже выполняет необходимую предобработку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nips12 = scipy.io.loadmat('nips12raw_str602.mat', squeeze_me=True)\n",
    "\n",
    "# матрица размера <число документов> x <число слов>\n",
    "counts = nips12['counts'].T\n",
    "\n",
    "# оставим 2013 (~2000) наиболее употребимих слов\n",
    "words_mask = np.ravel(counts.sum(axis=0) >= 121)\n",
    "counts = counts[:, words_mask]\n",
    "\n",
    "# отображение id -> word (необходимо для gensim)\n",
    "nips12_id2word = {i: w for (i, w) in enumerate(nips12['wl'][words_mask])}\n",
    "\n",
    "# отображение word -> id (необходимо для pyLDAvis)\n",
    "nips12_word2id = {w: i for (i, w) in enumerate(nips12['wl'][words_mask])}\n",
    "\n",
    "# Год проведения конференции. Значение 0 соответсвует 1988, 1 - 1989, и т.д.\n",
    "nips12_issue = np.array([int(name[4:6]) for name in nips12['docnames']])\n",
    "\n",
    "# Заголовки статей\n",
    "nips12_titles = nips12['ptitles']\n",
    "\n",
    "# Полный корпус в формате gensim\n",
    "full_corpus = gensim.matutils.Scipy2Corpus(counts)\n",
    "\n",
    "stream = np.random.RandomState(seed=123)\n",
    "subset_mask = stream.rand(counts.shape[0]) <= 0.1\n",
    "\n",
    "# Маленький корпус из 10% случайных статей для ускорения экспериментов\n",
    "small_corpus = gensim.matutils.Scipy2Corpus(counts[subset_mask, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim использует итеративный подход к выводу в модели LDA. Для получения новых значений вариационных параметров выполняется `iterations` итераций вариационного вывода. Далее, новые значения \"блэндятся\" со старыми (значениями из предыдущей итерации EM-алгоритма) посредством вычисления взвешенного среднего. Эта процедура повторяется `num_passes` раз. Такой подход позволяет предотвратить \"застревание\" метода в локальных оптимумах.\n",
    "\n",
    "Используйте следующий шаблон для запуска LDA модели в Gensim. Сейчас мы используем подвыборку для ускорения вычислений.\n",
    "\n",
    "Замечание: нижняя оценка связана с метрикой perplexity, которая обычно используется в естественных языках: $perplexity = exp(-bound)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10  # число тем в модели LDA\n",
    "alpha = [0.1] * num_topics  # параметры априорного распределения Дирихле над распределениями документ/тема\n",
    "iterations = 50  # число итераций вариационного вывода\n",
    "num_passes = 5  # число проходов по датасету\n",
    "\n",
    "\n",
    "small_lda = gensim.models.LdaModel(\n",
    "    corpus=small_corpus,\n",
    "    passes=num_passes,\n",
    "    num_topics=num_topics,\n",
    "    alpha=alpha,\n",
    "    iterations=iterations,\n",
    "    id2word=nips12_id2word,\n",
    "    eval_every=0,\n",
    "    random_state=42\n",
    ")\n",
    "print('ELBO = {0:.4f}'.format(small_lda.bound(small_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуйте влияние значений параметров `iterations` и `num_passes` на значние нижней оценки обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуйте чувствительность нижней вариационную оценки к параметру априорного распределения $\\alpha$. Используйте симметричные значения $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Обучите лучшую найденую модель на полной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10  # число тем в модели LDA\n",
    "alpha = [0.1] * num_topics  # параметры априорного распределения Дирихле над распределениями документ/тема\n",
    "iterations = 1  # число итераций вариационного вывода\n",
    "num_passes = 1  # число проходов по датасету\n",
    "\n",
    "lda = gensim.models.LdaModel(\n",
    "    corpus=full_corpus,\n",
    "    passes=num_passes,\n",
    "    num_topics=num_topics,\n",
    "    alpha=alpha,\n",
    "    iterations=iterations,\n",
    "    id2word=nips12_id2word,\n",
    "    eval_every=0,\n",
    "    random_state=42,    \n",
    ")\n",
    "print('ELBO = {0:.4f}'.format(lda.bound(full_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлеките вариационные параметры $\\gamma$ &mdash; параметры вариационной аппроксимации апостериорных вероятностей тем для документов: $q(\\Theta_d) = Dir(\\Theta_d | \\gamma_d)$.\n",
    "\n",
    "Нормализуйте их так, чтобы получить вероятностное распределение над темами для каждого документа (средние значения вероятностей в соответствии с распределением Дирихле)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, _ = lda.inference(full_corpus)\n",
    "#нормализуйте gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите полученное апостериорное распределение вероятностей тем для нескольких документов. Сделайте это для документов разных годов. Меняется ли разреженность тем с течением времени? Как можно это объяснить?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите наиболее вероятные слова и наиболее вероятные документы для каждой темы. Воспользуйтесь функциями `lda.num_topics`, `lda.show_topic(topic, topn=10)`. Используйте нормализованные параметры $\\gamma$, вычисленные ранее.\n",
    "\n",
    "Проанализируйте результат. Как вы можете интерпретировать темы? Напишите ваши интерпретации хотя бы для трёх тем.\n",
    "\n",
    "Замечание. Если вы нашли интересную статью в списке, вы можете скачать её онлайн, публикации конференции NIPS доступны бесплатно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите среднюю вероятность тем для каждого года. Проанализируйте какие темы становятся более популярны с теченим времени, а какие, наоборот, теряют популярность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте следующий код для отображения тем, найденных LSI (Latent Semantic Indexing) &mdash; невероятностной тематической моделью. Как можно интерпретироват полученные темы? Сравните время работы методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(full_corpus, num_topics=num_topics, id2word=nips12_id2word)\n",
    "lsi.print_topics(10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте следующий код для изображения тем вашей лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDictionary():\n",
    "    def __init__(self, word2id):\n",
    "        self.token2id = word2id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.token2id)\n",
    "\n",
    "    \n",
    "class MyScipy2Corpus(gensim.matutils.Scipy2Corpus):\n",
    "    def __len__(self):\n",
    "        return self.vecs.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('model.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установите библиотеку `pyLDAvis` с помощью `pip`\n",
    "\n",
    "**Найдите две наиболее похожие темы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda = gensim.models.LdaModel.load('model.dat')\n",
    "my_full_corpus = MyScipy2Corpus(counts[subset_mask, :])\n",
    "my_dictionary = MyDictionary(nips12_word2id)\n",
    "data = pyLDAvis.gensim.prepare(lda, my_full_corpus, my_dictionary)\n",
    "pyLDAvis.display(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
